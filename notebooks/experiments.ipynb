{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import warnings\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from scipy import stats\n",
    "from datetime import date\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Set, Tuple\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "\n",
    "\n",
    "DATE_LIMIT = date(2023, 12, 31)\n",
    "BASE_PATH = os.path.dirname(os.getcwd())\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "USER_DATA_READ=f\"{BASE_PATH}/data/users-details-2023.csv\"\n",
    "USER_DATA_SAVE=f\"{BASE_PATH}/data/users.parquet\"\n",
    "\n",
    "ANIME_DATA_READ = f\"{BASE_PATH}/data/anime-dataset-2023.csv\"\n",
    "ANIME_DATA_SAVE = f\"{BASE_PATH}/data/animes.parquet\"\n",
    "\n",
    "SCORE_DATA_READ = f\"{BASE_PATH}/data/users-score-2023.csv\"\n",
    "SCORE_DATA_SAVE = f\"{BASE_PATH}/data/scores.parquet\"\n",
    "\n",
    "FINAL_DATASET_CUT6_BASIC_USER_DATA = f\"{BASE_PATH}/data/scores-cut6-basic.parquet\"\n",
    "FINAL_DATASET_CUT7_BASIC_USER_DATA = f\"{BASE_PATH}/data/scores-cut7-basic.parquet\"\n",
    "FINAL_DATASET_CUT8_BASIC_USER_DATA = f\"{BASE_PATH}/data/scores-cut8-basic.parquet\"\n",
    "\n",
    "FINAL_DATASET_CUT6_FULL_USER_DATA = f\"{BASE_PATH}/data/scores-cut6-full.parquet\"\n",
    "FINAL_DATASET_CUT7_FULL_USER_DATA = f\"{BASE_PATH}/data/scores-cut7-full.parquet\"\n",
    "FINAL_DATASET_CUT8_FULL_USER_DATA = f\"{BASE_PATH}/data/scores-cut8-full.parquet\"\n",
    "\n",
    "EXPERIMENT_LOG = f\"{BASE_PATH}/data/experiment-log.txt\"\n",
    "RESULTS_DIR = f\"{BASE_PATH}/data/results\"\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseReader:\n",
    "    def __init__(self, read_path: str, save_path: str):\n",
    "        self.file_path = read_path\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def to_parquet(self, df: pd.DataFrame) -> None:\n",
    "        df.to_parquet(self.save_path, index=False)\n",
    "\n",
    "    def get_stats(self, df: pd.DataFrame, columns: List[str]) -> dict:\n",
    "        result = dict()\n",
    "        for c in columns:\n",
    "            result[c] = {\n",
    "                \"hist\": df[c].value_counts(dropna=False).to_dict(),\n",
    "                \"max\": df[c].max(skipna=True) if df[c].dtype != \"O\" else 0,\n",
    "                \"mean\": df[c].mean(skipna=True) if df[c].dtype != \"O\" else 0,\n",
    "                \"median\": df[c].median(skipna=True) if df[c].dtype != \"O\" else 0,\n",
    "                \"min\": df[c].min(skipna=True) if df[c].dtype != \"O\" else 0\n",
    "            }\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def show_stats(self, result: dict) -> None:\n",
    "        for column in result.keys():\n",
    "            # Exibe estatísticas descritivas básicas\n",
    "            print(f\"Estatística descritiva de \\\"{column}\\\"\")\n",
    "            print(f\"Mínimo: {result[column][\"min\"]}\")\n",
    "            print(f\"Média: {result[column][\"mean\"]}\")\n",
    "            print(f\"Mediana: {result[column][\"median\"]}\")\n",
    "            print(f\"Máximo: {result[column][\"max\"]}\")\n",
    "\n",
    "            # Avalia a quantidade de nulos\n",
    "            count = 0\n",
    "            null = 0\n",
    "            for k in result[column][\"hist\"].keys():\n",
    "                count = count + result[column][\"hist\"][k]\n",
    "                if type(k) == float and np.isnan(k):\n",
    "                    null = result[column][\"hist\"][k]\n",
    "            percent = round(null * 100 / count, 2) if count > 0 else 0\n",
    "            print(f\"Quantidade de nulos: {null} ({percent}%)\")\n",
    "\n",
    "            # Exibe uma linha de separação\n",
    "            print(\"*\" * 40, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserReader(BaseReader):\n",
    "    def __init__(self, read_path: str, save_path: str):\n",
    "        super().__init__(read_path, save_path)\n",
    "\n",
    "    def first_process(self) -> pd.DataFrame:\n",
    "        # Carrega os dados, removendo colunas não utilizadas\n",
    "        remove_columns = [\n",
    "            \"Username\", \"Location\", \"Joined\",\n",
    "            \"On Hold\", \"Plan to Watch\", \"Rewatched\"\n",
    "        ]\n",
    "        df = pd.read_csv(self.file_path).drop(remove_columns, axis=1)\n",
    "\n",
    "        # Faz a troca de gênero definindo Male = 0 e Female = 1\n",
    "        def clear_gender(value: str) -> int:\n",
    "            if type(value) != str:\n",
    "                return None\n",
    "            return 0 if value.upper() == \"MALE\" else 1\n",
    "        df[\"Gender\"] = df[\"Gender\"].apply(clear_gender)\n",
    "\n",
    "        # Faz a conversão da data de nascimento na idade\n",
    "        def get_age(birth_date: str | float):\n",
    "            if type(birth_date) != str:\n",
    "                return None\n",
    "            return int((DATE_LIMIT - date.fromisoformat(birth_date.split(\"T\")[0])).days / 365)\n",
    "        df[\"age\"] = df[\"Birthday\"].apply(get_age)\n",
    "        df = df.drop([\"Birthday\"], axis=1)\n",
    "\n",
    "        # Faz a troca de nomes de colunas\n",
    "        df = df.rename(columns={\n",
    "            \"Mal ID\": \"user_id\",\n",
    "            \"Gender\": \"gender\",\n",
    "            \"Days Watched\": \"days_spent_with_anime\",\n",
    "            \"Mean Score\": \"mean_score\",\n",
    "            \"Watching\": \"current_anime_wathing\",\n",
    "            \"Completed\": \"total_anime_watched\",\n",
    "            \"Dropped\": \"dropped_anime\",\n",
    "            \"Total Entries\": \"anime_in_list\",\n",
    "            \"Episodes Watched\": \"episodes_watched\"\n",
    "        })\n",
    "\n",
    "        # Salva o arquivo limpo\n",
    "        return df\n",
    "\n",
    "    def remove_nulls(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        original_rows = len(df)\n",
    "        df = df.dropna()\n",
    "        new_rows = len(df)\n",
    "        percent = round((original_rows - new_rows) * 100 / original_rows, 2)\n",
    "        print(f\"Remoção de {original_rows - new_rows} linhas ({percent}%)\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_user_analysis():\n",
    "    reader = UserReader(USER_DATA_READ, USER_DATA_SAVE)\n",
    "    df_user = reader.first_process()\n",
    "\n",
    "    stats = reader.get_stats(\n",
    "        df_user,\n",
    "        [\n",
    "            \"gender\", \"days_spent_with_anime\", \"mean_score\",\n",
    "            \"current_anime_wathing\", \"total_anime_watched\",\n",
    "            \"dropped_anime\", \"anime_in_list\", \"episodes_watched\", \"age\"\n",
    "        ]\n",
    "    )\n",
    "    reader.show_stats(stats)\n",
    "\n",
    "    df_user = reader.remove_nulls(df_user)\n",
    "    reader.to_parquet(df_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute_user_analysis()\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimeReader(BaseReader):\n",
    "    def __init__(self, read_path: str, save_path: str):\n",
    "        super().__init__(read_path, save_path)\n",
    "\n",
    "    def first_process(self) -> pd.DataFrame:\n",
    "        # Carrega dados\n",
    "        df = pd.read_csv(self.file_path)\n",
    "\n",
    "        # Remove colunas não utilizadas\n",
    "        use_columns = [\"anime_id\", \"Genres\", \"Episodes\", \"Source\", \"Duration\"]\n",
    "        df = df[use_columns]\n",
    "\n",
    "        # Faz a conversão do texto de duração para o valor numérico\n",
    "        def extract_duration(description: str):\n",
    "            if description.upper() == \"UNKNOWN\":\n",
    "                return np.nan\n",
    "            numbers = re.findall(r\"[0-9]+\", description)\n",
    "            if len(numbers) == 2:\n",
    "                return int(numbers[0]) * 60 + int(numbers[1])\n",
    "            else:\n",
    "                return int(numbers[0])\n",
    "        df[\"Duration\"] = df[\"Duration\"].apply(extract_duration)\n",
    "\n",
    "        # Converte o número de episódios em números e remove nulos\n",
    "        df[\"Episodes\"] = df[\"Episodes\"].apply(lambda x: float(x) if x.upper() != \"UNKNOWN\" else np.nan).astype(\"float64\")\n",
    "\n",
    "        # Aplica uma padronização nos nomes dos materiais originais\n",
    "        def standard_source(source: str):\n",
    "            conv_source = {\n",
    "                \"4-koma manga\": \"manga\",\n",
    "                \"Book\": \"book\",\n",
    "                \"Card game\": \"game\",\n",
    "                \"Game\": \"game\",\n",
    "                \"Light novel\": \"novel\",\n",
    "                \"Manga\": \"manga\",\n",
    "                \"Mixed media\": \"other\",\n",
    "                \"Music\": \"other\",\n",
    "                \"Novel\": \"novel\",\n",
    "                \"Original\": \"original\",\n",
    "                \"Other\": \"other\",\n",
    "                \"Picture book\": \"other\",\n",
    "                \"Radio\": \"other\",\n",
    "                \"Unknown\": np.nan,\n",
    "                \"Visual novel\": \"visual_novel\",\n",
    "                \"Web manga\": \"manga\",\n",
    "                \"Web novel\": \"novel\"\n",
    "            }\n",
    "            try:\n",
    "                return conv_source[source]\n",
    "            except:\n",
    "                return np.nan\n",
    "        df[\"Source\"] = df[\"Source\"].apply(standard_source)\n",
    "\n",
    "        # Resolve nomenclatura de gêneros\n",
    "        df[\"Genres\"] = df[\"Genres\"].apply(lambda x: np.nan if x == \"UNKNOWN\" else x)\n",
    "\n",
    "        # Faz a troca dos nomes das colunas\n",
    "        df = df.rename(columns={\n",
    "            \"Genres\": \"genres\",\n",
    "            \"Episodes\": \"episodes\",\n",
    "            \"Source\": \"source\",\n",
    "            \"Duration\": \"duration\"\n",
    "        })\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def remove_nulls(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        return df.dropna(subset=[\"source\", \"duration\", \"episodes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_anime_analysis():\n",
    "    anime_reader = AnimeReader(ANIME_DATA_READ, ANIME_DATA_SAVE)\n",
    "\n",
    "    df_anime = anime_reader.first_process()\n",
    "    stats = anime_reader.get_stats(\n",
    "        df_anime,\n",
    "        [\"genres\", \"episodes\", \"source\", \"duration\"]\n",
    "    )\n",
    "    anime_reader.show_stats(stats)\n",
    "    df_anime = anime_reader.remove_nulls(df_anime)\n",
    "    anime_reader.to_parquet(df_anime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute_anime_analysis()\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoreReader(BaseReader):\n",
    "    def __init__(self, read_path: str, save_path: str, user_path: str, anime_path: str):\n",
    "        super().__init__(read_path, save_path)\n",
    "        self.anime_path = anime_path\n",
    "        self.user_path = user_path\n",
    "\n",
    "    def make_dataset(self, rating_cut=7, user_merge_mode=1) -> pd.DataFrame:\n",
    "        # Verifica integridade dos parâmetros\n",
    "        if rating_cut > 10 or rating_cut < 1:\n",
    "            raise Exception(\"O corte da classificação deve ser entre 1 e 10\")\n",
    "        \n",
    "        if user_merge_mode not in [1, 2]:\n",
    "            raise Exception(\"O modo de merge de usuário deve ser 1 ou 2\")\n",
    "        \n",
    "        # Carrega os dados dos scores, limpando as colunas não utilizadas\n",
    "        df = pd.read_csv(self.file_path)\n",
    "        df = df.drop([\"Username\", \"Anime Title\"], axis=1)\n",
    "\n",
    "        # Carrega os dados de usuários e animes\n",
    "        users = pd.read_parquet(self.user_path)\n",
    "        animes = pd.read_parquet(self.anime_path)\n",
    "\n",
    "        # Recupera todos os gêneros possíveis\n",
    "        genres = [[s.strip() for s in g.split(\",\")] for g in animes[\"genres\"].values if g is not None]\n",
    "        genres: Set[str] = set(itertools.chain.from_iterable(genres))\n",
    "\n",
    "        # Define a função de verificação de gênero\n",
    "        # Os dados de gêneros são carregados como uma string,\n",
    "        # com as categorias separadas por vírgula\n",
    "        def verify_genre(genres: str | None, genre: str) -> int:\n",
    "            if genres is None:\n",
    "                return 0\n",
    "            \n",
    "            genres = [s.lower().strip() for s in genres.split(\",\")]\n",
    "            return 1 if genre.lower() in genres else 0\n",
    "\n",
    "        # Aplica o encoder para gêneros de animes\n",
    "        for genre in genres:\n",
    "            column = f\"genre_{\"_\".join(genre.lower().split(\" \"))}\"\n",
    "            animes[column] = animes[\"genres\"].apply(lambda x: verify_genre(x, genre))\n",
    "        animes = animes.drop([\"genres\"], axis=1)\n",
    "\n",
    "        # Define um encoder para o material original do anime\n",
    "        encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "        encoder.fit(animes[[\"source\"]])\n",
    "\n",
    "        # Atualiza os dados de anime com o encoder de material original\n",
    "        encoder_df = pd.DataFrame(\n",
    "            encoder.transform(animes[[\"source\"]]),\n",
    "            columns=encoder.get_feature_names_out()\n",
    "        )\n",
    "        animes = pd.concat((animes, encoder_df), axis=1)\n",
    "        animes = animes.drop([\"source\"], axis=1)\n",
    "\n",
    "        # Executa o merge com os dados de usuários\n",
    "        # user_merge_mode = 1 faz com que apenas os dados básicos sejam usados\n",
    "        # user_merge_mode = 2 utiliza todos os dados de usuários\n",
    "        if user_merge_mode == 1:\n",
    "            users = users[[\"user_id\", \"gender\", \"age\"]]\n",
    "\n",
    "        if user_merge_mode == 2:\n",
    "            users = users[[\"user_id\", \"gender\", \"age\", \"days_spent_with_anime\", \"total_anime_watched\", \"dropped_anime\", \"mean_score\"]]\n",
    "        \n",
    "        df = df.merge(users, how=\"inner\", on=\"user_id\")\n",
    "\n",
    "        # Executa o merge com os dados de animes\n",
    "        df = df.merge(animes, how=\"inner\", on=\"anime_id\")\n",
    "\n",
    "        # Faz a criação da coluna target\n",
    "        df[\"target\"] = df[\"rating\"].apply(lambda x: 1 if x > rating_cut else 0)\n",
    "        df = df.drop([\"rating\"], axis=1)\n",
    "\n",
    "        # Finaliza o processo, removendo colunas de ID\n",
    "        df = df.drop([\"user_id\", \"anime_id\"], axis=1)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets():\n",
    "    result_files = [\n",
    "        FINAL_DATASET_CUT6_BASIC_USER_DATA,\n",
    "        FINAL_DATASET_CUT7_BASIC_USER_DATA,\n",
    "        FINAL_DATASET_CUT8_BASIC_USER_DATA,\n",
    "        FINAL_DATASET_CUT6_FULL_USER_DATA,\n",
    "        FINAL_DATASET_CUT7_FULL_USER_DATA,\n",
    "        FINAL_DATASET_CUT8_FULL_USER_DATA\n",
    "    ]\n",
    "\n",
    "    for save_path in result_files:\n",
    "        score_reader = ScoreReader(\n",
    "            SCORE_DATA_READ,\n",
    "            save_path,\n",
    "            USER_DATA_SAVE,\n",
    "            ANIME_DATA_SAVE\n",
    "        )\n",
    "        scores = score_reader.make_dataset()\n",
    "        score_reader.to_parquet(scores)\n",
    "\n",
    "        del scores\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_datasets()\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model4Layers(nn.Module):\n",
    "    def __init__(self, n_features: int, n_classes=2, n_neurons=16):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(n_features, n_neurons)\n",
    "        self.fc2 = nn.Linear(n_neurons, n_neurons)\n",
    "        self.fc3 = nn.Linear(n_neurons, n_neurons)\n",
    "        self.fc4 = nn.Linear(n_neurons, n_classes)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.out = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class Model8Layers(nn.Module):\n",
    "    def __init__(self, n_features: int, n_classes=2, n_neurons=16):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(n_features, n_neurons)\n",
    "        self.fc2 = nn.Linear(n_neurons, n_neurons)\n",
    "        self.fc3 = nn.Linear(n_neurons, n_neurons)\n",
    "        self.fc4 = nn.Linear(n_neurons, n_neurons)\n",
    "        self.fc5 = nn.Linear(n_neurons, n_neurons)\n",
    "        self.fc6 = nn.Linear(n_neurons, n_neurons)\n",
    "        self.fc7 = nn.Linear(n_neurons, n_neurons)\n",
    "        self.fc8 = nn.Linear(n_neurons, n_classes)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.out = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc5(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc6(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc7(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc8(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Manager:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get_dataset(self, read_path: str, sample=0.2):\n",
    "        # Carrega dados processados\n",
    "        df = pd.read_parquet(read_path).sample(frac=sample)\n",
    "        X = df.drop([\"target\"], axis=1).values\n",
    "        y = df[\"target\"].values\n",
    "\n",
    "        # Faz a divisão entre treino e teste\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "        # Aplica a padronização de valores\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        # Faz a transformação de numpy array para tensor\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "        y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "        # Instancia dataset de tensores\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "        # Instancia loader de tensores\n",
    "        train_loader = DataLoader(train_dataset, batch_size=1000, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "        return train_dataset, test_dataset, train_loader, test_loader\n",
    "    \n",
    "    def execute(self, train_dataset: DataLoader, train_loader: DataLoader, epochs=100, n_neurons=16, arch=1):\n",
    "        # Garante consistência da arquitetura\n",
    "        if arch not in [1, 2]:\n",
    "            raise Exception(\"As arquiteturas válidas são 1 e 2\")\n",
    "        \n",
    "        # Regitra o tempo de início do treinamento\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Carrega dados e inicializa modelo\n",
    "        classes_ = len(train_dataset.tensors[1].unique())\n",
    "        if arch == 1:\n",
    "            model = Model4Layers(\n",
    "                n_features=train_dataset.tensors[0].shape[1],\n",
    "                n_classes=classes_,\n",
    "                n_neurons=n_neurons\n",
    "            )\n",
    "        elif arch == 2:\n",
    "            model = Model8Layers(\n",
    "                n_features=train_dataset.tensors[0].shape[1],\n",
    "                n_classes=classes_,\n",
    "                n_neurons=n_neurons\n",
    "            )\n",
    "\n",
    "        # Define o modo de otimização\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in range(0, epochs):\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            model.train()\n",
    "            count_batch = 0\n",
    "            limit_batch = (train_dataset.tensors[0].shape[0] // train_loader.batch_size) + 1\n",
    "\n",
    "            for inputs, labels in train_loader:\n",
    "                percent = round(count_batch * 100 / limit_batch, 2)\n",
    "                print(f\"Epoch {epoch + 1} Batch {count_batch + 1} ({percent}%)\", end=\"\\r\")\n",
    "                inputs = inputs\n",
    "                labels = labels\n",
    "\n",
    "                # Inicia os gradientes e calcula a predição\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                pred_labels = torch.argmax(outputs, dim=1)\n",
    "\n",
    "                # Teoricamente, seria preciso passar as labels do dataset para o\n",
    "                # padrão one hot encoder, porém a camada softmax no modelo já\n",
    "                # resolve isso.\n",
    "                # oh_labels = F.one_hot(labels.long())\n",
    "                # loss = criterion(outputs, torch.reshape(oh_labels, (oh_labels.size()[0], classes_)).float())\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Calcula os gradientes e atualiza os pesos\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Fal a atualização das estatísticas de acompanhamento\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(pred_labels == labels.data).item()\n",
    "                count_batch = count_batch + 1\n",
    "\n",
    "            # Exibe estatísticas de acompanhamento\n",
    "            num_samples = len(train_dataset)\n",
    "            epoch_loss = running_loss / num_samples\n",
    "            epoch_accuracy = running_corrects / num_samples\n",
    "            print(f\"Epoch {epoch + 1}: Loss {epoch_loss:.3f} Acurácia {epoch_accuracy:.3f}\")\n",
    "\n",
    "        # Calcula o tempo de execução do treinamento\n",
    "        end_time = time.time()\n",
    "        train_time = end_time - start_time\n",
    "\n",
    "        return model, train_time, epoch_loss\n",
    "    \n",
    "    def compute_test(self, model: nn.Module, test_loader: DataLoader, train_time: float, train_loss: float) -> dict:\n",
    "        # Define modelo como avaliação e inicia as listas de labels\n",
    "        model.eval()\n",
    "        pred_labels_all = []\n",
    "        true_labels_all = []\n",
    "\n",
    "        # Passa pelo loader para cálculo das predições\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            pred_labels = torch.argmax(outputs, dim=1)\n",
    "            pred_labels_all.append(pred_labels)\n",
    "            true_labels_all.append(labels)\n",
    "\n",
    "        # Concatena os resultados\n",
    "        pred_labels = torch.cat(pred_labels_all, dim=0).cpu().numpy()\n",
    "        true_labels = torch.cat(true_labels_all, dim=0).numpy()\n",
    "\n",
    "        # Registra dados no dicionário de dados\n",
    "        return {\n",
    "            \"train_time\": train_time,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"metrics\": {\n",
    "                \"accuracy\": (pred_labels == true_labels).mean(),\n",
    "                \"f1-score\": f1_score(true_labels, pred_labels, pos_label=1, average=\"binary\"),\n",
    "                \"recall-score\": recall_score(true_labels, pred_labels, pos_label=1, average=\"binary\"),\n",
    "                \"precission-score\": precision_score(true_labels, pred_labels, pos_label=1, average=\"binary\")\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_experiments():\n",
    "    # Define os parâmetros dos experimentos\n",
    "    archs_set = [1, 2]\n",
    "    neurons_set = [16]\n",
    "    sample_data = [0.1, 0.2]\n",
    "    epochs = [10]\n",
    "    repeat = 5\n",
    "    data_paths = [\n",
    "        FINAL_DATASET_CUT6_BASIC_USER_DATA,\n",
    "        FINAL_DATASET_CUT7_BASIC_USER_DATA,\n",
    "        FINAL_DATASET_CUT8_BASIC_USER_DATA,\n",
    "        FINAL_DATASET_CUT6_FULL_USER_DATA,\n",
    "        FINAL_DATASET_CUT7_FULL_USER_DATA,\n",
    "        FINAL_DATASET_CUT8_FULL_USER_DATA\n",
    "    ]\n",
    "\n",
    "    # Verifica o log de experimentos\n",
    "    if not os.path.exists(EXPERIMENT_LOG):\n",
    "        with open(EXPERIMENT_LOG, \"w\") as file:\n",
    "            file.write(\"dataset_type,arch,neurons,sample,epochs,iteration,weight_file,predict_file\\n\")\n",
    "\n",
    "    # Função auxiliar: abre o log e verifica registros\n",
    "    def verify(dataset_type: str, arch: int, neurons: int, sample: float, epochs: int, iteration: int):\n",
    "        exist = False\n",
    "        with open(EXPERIMENT_LOG, \"r\") as file:\n",
    "            row = file.readline()\n",
    "            while row:\n",
    "                row_dataset_type, row_arch, row_neurons, row_sample, row_epochs, row_iteration, _, _ = row.split(\",\")\n",
    "                row_params = [row_dataset_type, row_arch, row_neurons, row_sample, row_epochs, row_iteration]\n",
    "                search_params = [str(dataset_type), str(arch), str(neurons), str(sample), str(epochs), str(iteration)]\n",
    "                #print(row_params, search_params)\n",
    "                \n",
    "                if row_params == search_params:\n",
    "                    exist = True\n",
    "                    break\n",
    "\n",
    "                row = file.readline()\n",
    "\n",
    "        return exist\n",
    "\n",
    "    for data_path in data_paths:\n",
    "        # Tipo de dataset utilizado\n",
    "        dataset_type = data_path.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "        for neurons in neurons_set:\n",
    "            # Quantidade de neurônios das camadas internas\n",
    "\n",
    "            for sample in sample_data:\n",
    "                # Porção dos dados fracionados\n",
    "\n",
    "                for epoch in epochs:\n",
    "                    # Quantidade de épocas do treinamento\n",
    "\n",
    "                    for arch in archs_set:\n",
    "                        # Profundidade da rede\n",
    "\n",
    "                        for i in range(0, repeat):\n",
    "                            # Verifica se o experimento já foi executado\n",
    "                            if verify(dataset_type, arch, neurons, sample, epoch, i):\n",
    "                                continue\n",
    "\n",
    "                            # Registra todos os dados do experimento\n",
    "                            unique_name = int(time.time())\n",
    "                            weight_path = f\"{RESULTS_DIR}/{unique_name}.pth\"\n",
    "                            predict_path = f\"{RESULTS_DIR}/{unique_name}.json\"\n",
    "                            experiment_data = [\n",
    "                                    dataset_type,\n",
    "                                    str(arch),\n",
    "                                    str(neurons),\n",
    "                                    str(sample),\n",
    "                                    str(epoch),\n",
    "                                    str(i),\n",
    "                                    f\"{unique_name}.pth\",\n",
    "                                    f\"{unique_name}.json\"\n",
    "                                ]\n",
    "\n",
    "                            # Log de execução\n",
    "                            print(f\"Execução do experimento {\",\".join(experiment_data[:-2])}\".upper())\n",
    "\n",
    "                            # Repetição do experimento\n",
    "                            process = Manager()\n",
    "                            train_dataset, test_dataset, train_loader, test_loader = process.get_dataset(data_path, sample=sample)\n",
    "                            gc.collect()\n",
    "                            model, train_time, train_loss = process.execute(train_dataset, train_loader, epochs=epoch, n_neurons=neurons, arch=arch)\n",
    "\n",
    "                            # Executa o teste do modelo\n",
    "                            results = process.compute_test(model, test_loader, train_time, train_loss)\n",
    "                            \n",
    "                            # Salva o json de métricas\n",
    "                            with open(predict_path, \"w+\") as file:\n",
    "                                file.write(json.dumps(results))\n",
    "\n",
    "                            # Salva os pesos do modelo\n",
    "                            torch.save(model.state_dict(), weight_path)\n",
    "\n",
    "                            # Registra no log\n",
    "                            with open(EXPERIMENT_LOG, \"a\") as file:\n",
    "                                file.write(\",\".join(experiment_data) + \"\\n\")\n",
    "\n",
    "                            # Libera memória\n",
    "                            del train_dataset, test_dataset, train_loader, test_loader\n",
    "                            gc.collect()\n",
    "                            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_analysis(\n",
    "    df: pd.DataFrame,\n",
    "    factor_columns: List[str],\n",
    "    analysis_column: str\n",
    "):\n",
    "    # Instancia o dataset de resposta\n",
    "    df_result = []\n",
    "\n",
    "    # Faz a criação dos fatores da execução\n",
    "    factors: List[List[Tuple[str, int|float|str]]] = []\n",
    "    values = dict()\n",
    "\n",
    "    for column in factor_columns:\n",
    "        values[column] = []\n",
    "        for value in df[column].unique():\n",
    "            values[column].append((column, value))\n",
    "\n",
    "    factors = list(itertools.product(*values.values()))\n",
    "\n",
    "    # Para cada fator, cria o subset de análise\n",
    "    for factor_list in factors:\n",
    "        factor_name = []\n",
    "        subset = df\n",
    "\n",
    "        for column, value in factor_list:\n",
    "            subset = subset.loc[subset[column] == value]\n",
    "            factor_name.append(f\"{column}={str(value)}\")\n",
    "        factor_name = \",\".join(factor_name)\n",
    "\n",
    "        # Encontra a quantidade de elementos da análise\n",
    "        elements = df[analysis_column].unique()\n",
    "        register = {\"factor\": factor_name}\n",
    "\n",
    "        # Percorre o conjunto filtrado pelo fator\n",
    "        for _, row in subset.iterrows():\n",
    "\n",
    "            # Acessa o arquivo de métricas\n",
    "            with open(f\"{RESULTS_DIR}/{row[\"predict_file\"]}\") as file:\n",
    "                result = json.load(file)\n",
    "\n",
    "            # Verifica qual item de análise será utilizado\n",
    "            for e in elements:\n",
    "                if row[analysis_column] == e:\n",
    "                    if e not in register.keys():\n",
    "                        register[e] = []\n",
    "                    register[e].append(result[\"metrics\"][\"f1-score\"])\n",
    "                    break\n",
    "        \n",
    "        # Executa o teste de média para cada combinação\n",
    "        combinations = list(itertools.combinations(elements, 2))\n",
    "        for column1, column2 in combinations:\n",
    "            register[f\"ttest-{column1}-{column2}\"] = stats.ttest_ind(\n",
    "                register[column1], register[column2]\n",
    "            ).pvalue\n",
    "\n",
    "        # Converte as listas para a média\n",
    "        for e in elements:\n",
    "            register[e] = np.mean(register[e])\n",
    "\n",
    "        # Salva os dados no dataset de resultados\n",
    "        df_result.append(register)\n",
    "\n",
    "    return pd.DataFrame(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(EXPERIMENT_LOG)\n",
    "df[\"cut\"] = df[\"dataset_type\"].apply(lambda x: x.split(\"-\")[1])\n",
    "df[\"features\"] = df[\"dataset_type\"].apply(lambda x: x.split(\"-\")[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeira comparação: existe diferença entre utilizar dados básicos e metadados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factor</th>\n",
       "      <th>basic</th>\n",
       "      <th>full</th>\n",
       "      <th>ttest-basic-full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arch=1,sample=0.1,cut=cut6</td>\n",
       "      <td>0.703058</td>\n",
       "      <td>0.709564</td>\n",
       "      <td>0.181639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arch=1,sample=0.1,cut=cut7</td>\n",
       "      <td>0.706680</td>\n",
       "      <td>0.704263</td>\n",
       "      <td>0.413272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arch=1,sample=0.1,cut=cut8</td>\n",
       "      <td>0.703752</td>\n",
       "      <td>0.708675</td>\n",
       "      <td>0.318417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arch=1,sample=0.2,cut=cut6</td>\n",
       "      <td>0.707050</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>0.433863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arch=1,sample=0.2,cut=cut7</td>\n",
       "      <td>0.706703</td>\n",
       "      <td>0.704651</td>\n",
       "      <td>0.514483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>arch=1,sample=0.2,cut=cut8</td>\n",
       "      <td>0.707439</td>\n",
       "      <td>0.707936</td>\n",
       "      <td>0.911095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>arch=2,sample=0.1,cut=cut6</td>\n",
       "      <td>0.707292</td>\n",
       "      <td>0.700698</td>\n",
       "      <td>0.105080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>arch=2,sample=0.1,cut=cut7</td>\n",
       "      <td>0.700951</td>\n",
       "      <td>0.705855</td>\n",
       "      <td>0.439372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>arch=2,sample=0.1,cut=cut8</td>\n",
       "      <td>0.707420</td>\n",
       "      <td>0.703235</td>\n",
       "      <td>0.439435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>arch=2,sample=0.2,cut=cut6</td>\n",
       "      <td>0.702501</td>\n",
       "      <td>0.706176</td>\n",
       "      <td>0.529896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>arch=2,sample=0.2,cut=cut7</td>\n",
       "      <td>0.705210</td>\n",
       "      <td>0.709543</td>\n",
       "      <td>0.324600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>arch=2,sample=0.2,cut=cut8</td>\n",
       "      <td>0.707960</td>\n",
       "      <td>0.705540</td>\n",
       "      <td>0.563122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        factor     basic      full  ttest-basic-full\n",
       "0   arch=1,sample=0.1,cut=cut6  0.703058  0.709564          0.181639\n",
       "1   arch=1,sample=0.1,cut=cut7  0.706680  0.704263          0.413272\n",
       "2   arch=1,sample=0.1,cut=cut8  0.703752  0.708675          0.318417\n",
       "3   arch=1,sample=0.2,cut=cut6  0.707050  0.704225          0.433863\n",
       "4   arch=1,sample=0.2,cut=cut7  0.706703  0.704651          0.514483\n",
       "5   arch=1,sample=0.2,cut=cut8  0.707439  0.707936          0.911095\n",
       "6   arch=2,sample=0.1,cut=cut6  0.707292  0.700698          0.105080\n",
       "7   arch=2,sample=0.1,cut=cut7  0.700951  0.705855          0.439372\n",
       "8   arch=2,sample=0.1,cut=cut8  0.707420  0.703235          0.439435\n",
       "9   arch=2,sample=0.2,cut=cut6  0.702501  0.706176          0.529896\n",
       "10  arch=2,sample=0.2,cut=cut7  0.705210  0.709543          0.324600\n",
       "11  arch=2,sample=0.2,cut=cut8  0.707960  0.705540          0.563122"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_analysis(\n",
    "    df,\n",
    "    factor_columns=[\"arch\", \"sample\", \"cut\"],\n",
    "    analysis_column=\"features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segunda comparação: existe diferença de onde fazer o corte de gostou/desgostou?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factor</th>\n",
       "      <th>cut6</th>\n",
       "      <th>cut7</th>\n",
       "      <th>cut8</th>\n",
       "      <th>ttest-cut6-cut7</th>\n",
       "      <th>ttest-cut6-cut8</th>\n",
       "      <th>ttest-cut7-cut8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arch=1,sample=0.1,features=basic</td>\n",
       "      <td>0.703058</td>\n",
       "      <td>0.706680</td>\n",
       "      <td>0.703752</td>\n",
       "      <td>0.424504</td>\n",
       "      <td>0.907202</td>\n",
       "      <td>0.562186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arch=1,sample=0.1,features=full</td>\n",
       "      <td>0.709564</td>\n",
       "      <td>0.704263</td>\n",
       "      <td>0.708675</td>\n",
       "      <td>0.116849</td>\n",
       "      <td>0.761126</td>\n",
       "      <td>0.104279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arch=1,sample=0.2,features=basic</td>\n",
       "      <td>0.707050</td>\n",
       "      <td>0.706703</td>\n",
       "      <td>0.707439</td>\n",
       "      <td>0.837969</td>\n",
       "      <td>0.910974</td>\n",
       "      <td>0.823197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arch=1,sample=0.2,features=full</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>0.704651</td>\n",
       "      <td>0.707936</td>\n",
       "      <td>0.922783</td>\n",
       "      <td>0.419435</td>\n",
       "      <td>0.455492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arch=2,sample=0.1,features=basic</td>\n",
       "      <td>0.707292</td>\n",
       "      <td>0.700951</td>\n",
       "      <td>0.707420</td>\n",
       "      <td>0.185875</td>\n",
       "      <td>0.972284</td>\n",
       "      <td>0.214052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>arch=2,sample=0.1,features=full</td>\n",
       "      <td>0.700698</td>\n",
       "      <td>0.705855</td>\n",
       "      <td>0.703235</td>\n",
       "      <td>0.375080</td>\n",
       "      <td>0.637364</td>\n",
       "      <td>0.688826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>arch=2,sample=0.2,features=basic</td>\n",
       "      <td>0.702501</td>\n",
       "      <td>0.705210</td>\n",
       "      <td>0.707960</td>\n",
       "      <td>0.654094</td>\n",
       "      <td>0.344183</td>\n",
       "      <td>0.485336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>arch=2,sample=0.2,features=full</td>\n",
       "      <td>0.706176</td>\n",
       "      <td>0.709543</td>\n",
       "      <td>0.705540</td>\n",
       "      <td>0.402114</td>\n",
       "      <td>0.884352</td>\n",
       "      <td>0.385400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             factor      cut6      cut7      cut8  \\\n",
       "0  arch=1,sample=0.1,features=basic  0.703058  0.706680  0.703752   \n",
       "1   arch=1,sample=0.1,features=full  0.709564  0.704263  0.708675   \n",
       "2  arch=1,sample=0.2,features=basic  0.707050  0.706703  0.707439   \n",
       "3   arch=1,sample=0.2,features=full  0.704225  0.704651  0.707936   \n",
       "4  arch=2,sample=0.1,features=basic  0.707292  0.700951  0.707420   \n",
       "5   arch=2,sample=0.1,features=full  0.700698  0.705855  0.703235   \n",
       "6  arch=2,sample=0.2,features=basic  0.702501  0.705210  0.707960   \n",
       "7   arch=2,sample=0.2,features=full  0.706176  0.709543  0.705540   \n",
       "\n",
       "   ttest-cut6-cut7  ttest-cut6-cut8  ttest-cut7-cut8  \n",
       "0         0.424504         0.907202         0.562186  \n",
       "1         0.116849         0.761126         0.104279  \n",
       "2         0.837969         0.910974         0.823197  \n",
       "3         0.922783         0.419435         0.455492  \n",
       "4         0.185875         0.972284         0.214052  \n",
       "5         0.375080         0.637364         0.688826  \n",
       "6         0.654094         0.344183         0.485336  \n",
       "7         0.402114         0.884352         0.385400  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_analysis(\n",
    "    df,\n",
    "    factor_columns=[\"arch\", \"sample\", \"features\"],\n",
    "    analysis_column=\"cut\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terceira comparação: existe diferença entre abordagens com diferentes profundidades?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factor</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>ttest-1-2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample=0.1,features=basic,cut=cut6</td>\n",
       "      <td>0.703058</td>\n",
       "      <td>0.707292</td>\n",
       "      <td>0.354873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample=0.1,features=basic,cut=cut7</td>\n",
       "      <td>0.706680</td>\n",
       "      <td>0.700951</td>\n",
       "      <td>0.226659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample=0.1,features=basic,cut=cut8</td>\n",
       "      <td>0.703752</td>\n",
       "      <td>0.707420</td>\n",
       "      <td>0.502527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample=0.1,features=full,cut=cut6</td>\n",
       "      <td>0.709564</td>\n",
       "      <td>0.700698</td>\n",
       "      <td>0.046537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample=0.1,features=full,cut=cut7</td>\n",
       "      <td>0.704263</td>\n",
       "      <td>0.705855</td>\n",
       "      <td>0.758477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sample=0.1,features=full,cut=cut8</td>\n",
       "      <td>0.708675</td>\n",
       "      <td>0.703235</td>\n",
       "      <td>0.264764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sample=0.2,features=basic,cut=cut6</td>\n",
       "      <td>0.707050</td>\n",
       "      <td>0.702501</td>\n",
       "      <td>0.403423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sample=0.2,features=basic,cut=cut7</td>\n",
       "      <td>0.706703</td>\n",
       "      <td>0.705210</td>\n",
       "      <td>0.649358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sample=0.2,features=basic,cut=cut8</td>\n",
       "      <td>0.707439</td>\n",
       "      <td>0.707960</td>\n",
       "      <td>0.893757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sample=0.2,features=full,cut=cut6</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>0.706176</td>\n",
       "      <td>0.643835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sample=0.2,features=full,cut=cut7</td>\n",
       "      <td>0.704651</td>\n",
       "      <td>0.709543</td>\n",
       "      <td>0.257530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sample=0.2,features=full,cut=cut8</td>\n",
       "      <td>0.707936</td>\n",
       "      <td>0.705540</td>\n",
       "      <td>0.610645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                factor         1         2  ttest-1-2\n",
       "0   sample=0.1,features=basic,cut=cut6  0.703058  0.707292   0.354873\n",
       "1   sample=0.1,features=basic,cut=cut7  0.706680  0.700951   0.226659\n",
       "2   sample=0.1,features=basic,cut=cut8  0.703752  0.707420   0.502527\n",
       "3    sample=0.1,features=full,cut=cut6  0.709564  0.700698   0.046537\n",
       "4    sample=0.1,features=full,cut=cut7  0.704263  0.705855   0.758477\n",
       "5    sample=0.1,features=full,cut=cut8  0.708675  0.703235   0.264764\n",
       "6   sample=0.2,features=basic,cut=cut6  0.707050  0.702501   0.403423\n",
       "7   sample=0.2,features=basic,cut=cut7  0.706703  0.705210   0.649358\n",
       "8   sample=0.2,features=basic,cut=cut8  0.707439  0.707960   0.893757\n",
       "9    sample=0.2,features=full,cut=cut6  0.704225  0.706176   0.643835\n",
       "10   sample=0.2,features=full,cut=cut7  0.704651  0.709543   0.257530\n",
       "11   sample=0.2,features=full,cut=cut8  0.707936  0.705540   0.610645"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_analysis(\n",
    "    df,\n",
    "    factor_columns=[\"sample\", \"features\", \"cut\"],\n",
    "    analysis_column=\"arch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quarta comparação: o sample de dados interfere na capacidade do modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factor</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>ttest-0.1-0.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arch=1,features=basic,cut=cut6</td>\n",
       "      <td>0.703058</td>\n",
       "      <td>0.707050</td>\n",
       "      <td>0.348973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arch=1,features=basic,cut=cut7</td>\n",
       "      <td>0.706680</td>\n",
       "      <td>0.706703</td>\n",
       "      <td>0.992050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arch=1,features=basic,cut=cut8</td>\n",
       "      <td>0.703752</td>\n",
       "      <td>0.707439</td>\n",
       "      <td>0.509266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arch=1,features=full,cut=cut6</td>\n",
       "      <td>0.709564</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>0.211191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arch=1,features=full,cut=cut7</td>\n",
       "      <td>0.704263</td>\n",
       "      <td>0.704651</td>\n",
       "      <td>0.912950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>arch=1,features=full,cut=cut8</td>\n",
       "      <td>0.708675</td>\n",
       "      <td>0.707936</td>\n",
       "      <td>0.833433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>arch=2,features=basic,cut=cut6</td>\n",
       "      <td>0.707292</td>\n",
       "      <td>0.702501</td>\n",
       "      <td>0.400205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>arch=2,features=basic,cut=cut7</td>\n",
       "      <td>0.700951</td>\n",
       "      <td>0.705210</td>\n",
       "      <td>0.410161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>arch=2,features=basic,cut=cut8</td>\n",
       "      <td>0.707420</td>\n",
       "      <td>0.707960</td>\n",
       "      <td>0.884968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>arch=2,features=full,cut=cut6</td>\n",
       "      <td>0.700698</td>\n",
       "      <td>0.706176</td>\n",
       "      <td>0.198687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>arch=2,features=full,cut=cut7</td>\n",
       "      <td>0.705855</td>\n",
       "      <td>0.709543</td>\n",
       "      <td>0.515265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>arch=2,features=full,cut=cut8</td>\n",
       "      <td>0.703235</td>\n",
       "      <td>0.705540</td>\n",
       "      <td>0.682302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            factor       0.1       0.2  ttest-0.1-0.2\n",
       "0   arch=1,features=basic,cut=cut6  0.703058  0.707050       0.348973\n",
       "1   arch=1,features=basic,cut=cut7  0.706680  0.706703       0.992050\n",
       "2   arch=1,features=basic,cut=cut8  0.703752  0.707439       0.509266\n",
       "3    arch=1,features=full,cut=cut6  0.709564  0.704225       0.211191\n",
       "4    arch=1,features=full,cut=cut7  0.704263  0.704651       0.912950\n",
       "5    arch=1,features=full,cut=cut8  0.708675  0.707936       0.833433\n",
       "6   arch=2,features=basic,cut=cut6  0.707292  0.702501       0.400205\n",
       "7   arch=2,features=basic,cut=cut7  0.700951  0.705210       0.410161\n",
       "8   arch=2,features=basic,cut=cut8  0.707420  0.707960       0.884968\n",
       "9    arch=2,features=full,cut=cut6  0.700698  0.706176       0.198687\n",
       "10   arch=2,features=full,cut=cut7  0.705855  0.709543       0.515265\n",
       "11   arch=2,features=full,cut=cut8  0.703235  0.705540       0.682302"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_analysis(\n",
    "    df,\n",
    "    factor_columns=[\"arch\", \"features\", \"cut\"],\n",
    "    analysis_column=\"sample\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
